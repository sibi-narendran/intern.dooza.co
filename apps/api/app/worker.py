"""
Singleton Scheduler Worker

Run as a SEPARATE PROCESS to prevent duplicate scheduled posts.
DO NOT run scheduler.start() in main.py!

Usage:
    python -m app.worker

This process ONLY runs the scheduler. It is designed to be:
1. Singleton - only one instance should run
2. Long-lived - runs until explicitly stopped
3. Separate - not part of the API server

Architecture:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  API Server (main.py)       ‚îÇ
    ‚îÇ  - Handles HTTP requests    ‚îÇ
    ‚îÇ  - Schedules jobs           ‚îÇ
    ‚îÇ  - Can scale horizontally   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ Add/remove jobs
                 ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  PostgreSQL                 ‚îÇ
    ‚îÇ  - apscheduler_jobs table   ‚îÇ
    ‚îÇ  - Shared between API and   ‚îÇ
    ‚îÇ    Worker                   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ Read jobs
                 ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Scheduler Worker (this)    ‚îÇ ‚óÑ‚îÄ‚îÄ SINGLETON
    ‚îÇ  - Executes scheduled jobs  ‚îÇ
    ‚îÇ  - Must be single instance  ‚îÇ
    ‚îÇ  - Prevents duplicate posts ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ Calls
                 ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  PublishService.execute()   ‚îÇ
    ‚îÇ  - Same service as API uses ‚îÇ
    ‚îÇ  - Zero Regret pattern      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Deployment:
    # Production: Two separate processes
    
    # 1. API Server (can scale horizontally)
    uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
    
    # 2. Scheduler Worker (SINGLETON - only one instance!)
    python -m app.worker

Docker Compose example:
    services:
      api:
        command: uvicorn app.main:app --host 0.0.0.0 --port 8000
        deploy:
          replicas: 2  # Can scale
      
      scheduler:
        command: python -m app.worker
        deploy:
          replicas: 1  # MUST be 1 - singleton!
"""

import asyncio
import signal
import sys
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)


async def startup_check():
    """Verify database connection and job store."""
    from app.core.database import get_supabase_client
    from app.scheduler.jobs import get_scheduled_jobs
    
    # Check database
    supabase = get_supabase_client()
    if not supabase:
        logger.error("‚ùå Database not available - cannot start scheduler")
        return False
    
    logger.info("‚úÖ Database connection OK")
    
    # List existing jobs
    jobs = get_scheduled_jobs()
    logger.info(f"üìã Found {len(jobs)} scheduled jobs in database")
    for job in jobs[:5]:  # Show first 5
        logger.info(f"   - Task {job['task_id']} scheduled for {job['next_run_time']}")
    if len(jobs) > 5:
        logger.info(f"   ... and {len(jobs) - 5} more")
    
    return True


async def run_scheduler():
    """Async entry point that runs the scheduler within an event loop."""
    from app.scheduler.scheduler import scheduler
    
    # Run startup check
    if not await startup_check():
        logger.error("Startup check failed, exiting")
        sys.exit(1)
    
    # Start the scheduler (now within a running event loop)
    logger.info("=" * 60)
    logger.info("üü¢ Starting scheduler...")
    scheduler.start()
    logger.info("‚úÖ Scheduler is now running")
    logger.info("   Waiting for scheduled jobs...")
    logger.info("=" * 60)
    logger.info("")
    
    # Keep running until interrupted
    stop_event = asyncio.Event()
    
    def handle_stop():
        logger.info("üõë Received shutdown signal...")
        stop_event.set()
    
    # Register signal handlers for graceful shutdown
    loop = asyncio.get_running_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, handle_stop)
    
    try:
        await stop_event.wait()
    finally:
        logger.info("Shutting down scheduler...")
        scheduler.shutdown(wait=True)
        logger.info("‚úÖ Scheduler stopped cleanly")


def main():
    """Main entry point for the scheduler worker."""
    logger.info("=" * 60)
    logger.info("üöÄ Starting Dooza Scheduler Worker")
    logger.info("=" * 60)
    logger.info("")
    logger.info("üìå IMPORTANT: This is a SINGLETON process.")
    logger.info("   Only ONE instance should run at a time.")
    logger.info("   Do NOT scale this horizontally!")
    logger.info("")
    logger.info(f"‚è∞ Started at: {datetime.utcnow().isoformat()}Z")
    logger.info("")
    logger.info("Supported platforms:")
    logger.info("   ‚Ä¢ Instagram")
    logger.info("   ‚Ä¢ Facebook")
    logger.info("   ‚Ä¢ LinkedIn")
    logger.info("   ‚Ä¢ TikTok")
    logger.info("   ‚Ä¢ YouTube")
    logger.info("")
    
    try:
        asyncio.run(run_scheduler())
    except KeyboardInterrupt:
        logger.info("Scheduler stopped by user")


if __name__ == "__main__":
    main()
